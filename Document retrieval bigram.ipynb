{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d3725cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import bigrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim import corpora, similarities, models\n",
    "import streamlit as st\n",
    "\n",
    "# Load your data from the Excel file\n",
    "df = pd.read_excel(\"amazon_review_processed_full.xlsx\")\n",
    "\n",
    "# Define a function to preprocess and tokenize the text\n",
    "def preprocess_text(row):\n",
    "    # Combine the title and review columns and convert to lowercase\n",
    "    title = row['Original title'] if not pd.isnull(row['Original title']) else ''\n",
    "    review = row['Original review'] if not pd.isnull(row['Original review']) else ''\n",
    "    text = (title + ' ' + review).lower()\n",
    "    \n",
    "    # Remove special characters and punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    \n",
    "    # Tokenization into unigrams\n",
    "    unigrams = word_tokenize(text)\n",
    "    \n",
    "    # Tokenization into bigrams\n",
    "    bigrams_list = list(bigrams(unigrams))\n",
    "    \n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_unigrams = [stemmer.stem(word) for word in unigrams]\n",
    "    stemmed_bigrams = [tuple(stemmer.stem(word) for word in bigram) for bigram in bigrams_list]\n",
    "    \n",
    "    # Define a set of stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Remove stopwords\n",
    "    unigrams_without_stopwords = [word for word in stemmed_unigrams if word not in stop_words]\n",
    "    \n",
    "    # Convert bigrams to strings and remove stopwords\n",
    "    bigrams_without_stopwords = [' '.join(bigram) for bigram in stemmed_bigrams if not any(word in stop_words for word in bigram)]\n",
    "    \n",
    "    # Join both unigrams and bigrams \n",
    "    tokens = unigrams_without_stopwords + bigrams_without_stopwords\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Apply the modified preprocessing function to your DataFrame\n",
    "df['Processed Text'] = df.apply(preprocess_text, axis=1)\n",
    "# Apply the preprocessing function to your DataFrame\n",
    "df['Processed Text'] = df.apply(preprocess_text, axis=1)\n",
    "\n",
    "# Create a dictionary from the tokenized content\n",
    "dictionary = corpora.Dictionary(df['Processed Text'])\n",
    "\n",
    "# Create a corpus (bag of words) from the tokenized content\n",
    "corpus = [dictionary.doc2bow(text) for text in df['Processed Text']]\n",
    "\n",
    "# To find the similarity scores, create a reverse index\n",
    "Index = similarities.SparseMatrixSimilarity(corpus, len(dictionary))\n",
    "\n",
    "# Create a TFIDF reverse index\n",
    "TFIDF = models.TfidfModel(corpus)\n",
    "corpus_TFIDF = [TFIDF[vec] for vec in corpus]\n",
    "Index_TFIDF = similarities.SparseMatrixSimilarity(corpus_TFIDF, len(dictionary))\n",
    "\n",
    "# A function to preprocess and tokenize the query\n",
    "def preprocess_query(query):\n",
    "    # Convert the query to lowercase\n",
    "    query = query.lower()\n",
    "    \n",
    "    # Remove special characters and punctuation\n",
    "    query = re.sub(r'[^\\w\\s]', ' ', query)\n",
    "    \n",
    "    # Tokenization into unigrams\n",
    "    unigrams = word_tokenize(query)\n",
    "    \n",
    "    # Tokenization into bigrams\n",
    "    bigrams_list = list(bigrams(unigrams))\n",
    "    \n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_unigrams = [stemmer.stem(word) for word in unigrams]\n",
    "    stemmed_bigrams = [tuple(stemmer.stem(word) for word in bigram) for bigram in bigrams_list]\n",
    "    \n",
    "    # Define a set of stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Remove stopwords\n",
    "    unigrams_without_stopwords = [word for word in stemmed_unigrams if word not in stop_words]\n",
    "    bigrams_without_stopwords = [' '.join(bigram) for bigram in stemmed_bigrams if not any(word in stop_words for word in bigram)]\n",
    "    \n",
    "    # Join both unigrams and bigrams \n",
    "    tokens = unigrams_without_stopwords + bigrams_without_stopwords\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "\n",
    "# A function to search and sort the results based on a query\n",
    "def search_and_sort(query):\n",
    "    # Import nltk inside the app logic\n",
    "    import nltk\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    from nltk.stem import PorterStemmer\n",
    "    nltk.download('punkt')\n",
    "    \n",
    "    # Preprocess the query and obtain a list of tokens\n",
    "    preprocessed_query = preprocess_query(query)\n",
    "\n",
    "    # Create a query vector using the same dictionary as the corpus\n",
    "    qVector = dictionary.doc2bow(preprocessed_query)\n",
    "\n",
    "    # Get its TFIDF from the same model as the corpus\n",
    "    qVectorTFIDF = TFIDF[qVector]\n",
    "\n",
    "    # Get the similarities from the two indexes (raw and TFIDF)\n",
    "    simRaw = Index[qVector]\n",
    "    simTFIDF = Index_TFIDF[qVectorTFIDF]\n",
    "\n",
    "    # Create a DataFrame to store the results\n",
    "    results_raw = pd.DataFrame({\n",
    "        'Document': range(len(df)),\n",
    "        'Raw Similarity Score': simRaw\n",
    "    })\n",
    "\n",
    "    results_tfidf = pd.DataFrame({\n",
    "        'Document': range(len(df)),\n",
    "        'TFIDF Similarity Score': simTFIDF\n",
    "    })\n",
    "\n",
    "    # Add the Similarity Score as a new column to the original DataFrame\n",
    "    df['Raw Similarity Score'] = results_raw['Raw Similarity Score']\n",
    "    df['TFIDF Similarity Score'] = results_tfidf['TFIDF Similarity Score']\n",
    "\n",
    "    # Sort the DataFrame by TFIDF Similarity Score in descending order\n",
    "    df_sorted_tfidf = df.sort_values(by='TFIDF Similarity Score', ascending=False)\n",
    "    \n",
    "    return df_sorted_tfidf[['Review Model', 'Review date', 'Review rating', 'Original title', 'Original review', 'TFIDF Similarity Score']].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "678c2a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [work, great, wa, easi, instal, work, great, w...\n",
       "1        [spunki, mid, size, printer, slower, print, sp...\n",
       "2        [ùô≤ùöïùöéùöäùöõ, ùöôùöõùöíùöóùöùùöú, ùôªùöòùöüùöé, ùöíùöù, ùô≤ùöïùöéùöäùöõ ùöôùöõùöíùöóùöùùöú, ùöôùöõùöíùöóùöùùöú...\n",
       "3        [shaq, know, talk, yup, thi, printer, slam, du...\n",
       "4        [user, friendli, would, think, someth, simpl, ...\n",
       "                               ...                        \n",
       "10204                    [quick, deliveri, quick deliveri]\n",
       "10205                    [awesom, printer, awesom printer]\n",
       "10206                                               [work]\n",
       "10207    [el, art√≠culo, lleg√≥, roto, el art√≠culo, art√≠c...\n",
       "10208    [new, printer, work, like, one, use, veri, goo...\n",
       "Name: Processed Text, Length: 10209, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Processed Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e565fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/vannguyen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Model</th>\n",
       "      <th>Review date</th>\n",
       "      <th>Review rating</th>\n",
       "      <th>Original title</th>\n",
       "      <th>Original review</th>\n",
       "      <th>TFIDF Similarity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>HP ENVY 6055e</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>3</td>\n",
       "      <td>Low Quality</td>\n",
       "      <td>this printer disconnects all the time. I spend...</td>\n",
       "      <td>0.392702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5238</th>\n",
       "      <td>Canon PIXMA TR4720</td>\n",
       "      <td>2023-08-16</td>\n",
       "      <td>2</td>\n",
       "      <td>Low quality printing</td>\n",
       "      <td>It was easy to install, but the printing job s...</td>\n",
       "      <td>0.360529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7068</th>\n",
       "      <td>Epson - ET-4850</td>\n",
       "      <td>2023-05-14</td>\n",
       "      <td>1</td>\n",
       "      <td>Very Poor Quality</td>\n",
       "      <td>I have had this printer for several months.  I...</td>\n",
       "      <td>0.265875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>Epson - ET-2800</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There‚Äôs only normal or high quality. There‚Äôs n...</td>\n",
       "      <td>0.262055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3767</th>\n",
       "      <td>Canon PIXMA TR4720</td>\n",
       "      <td>2023-06-07</td>\n",
       "      <td>1</td>\n",
       "      <td>Item had obviously been used. Ink cartridges w...</td>\n",
       "      <td>Printer did not produce quality copies. It arr...</td>\n",
       "      <td>0.238766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4819</th>\n",
       "      <td>Epson - XP-6100</td>\n",
       "      <td>2022-10-26</td>\n",
       "      <td>3</td>\n",
       "      <td>Could be better</td>\n",
       "      <td>Just taking it out of the box the printers pla...</td>\n",
       "      <td>0.230578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6853</th>\n",
       "      <td>HP ENVY Inspire 7255e</td>\n",
       "      <td>2023-03-29</td>\n",
       "      <td>3</td>\n",
       "      <td>Quality is poor unless you print a lot</td>\n",
       "      <td>I learned that you have to print often or else...</td>\n",
       "      <td>0.220677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>Epson - XP-6100</td>\n",
       "      <td>2023-08-20</td>\n",
       "      <td>1</td>\n",
       "      <td>Clunky</td>\n",
       "      <td>Low quality constructionSlow Print speedPainfu...</td>\n",
       "      <td>0.205049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2778</th>\n",
       "      <td>Epson - ET-3850</td>\n",
       "      <td>2023-03-07</td>\n",
       "      <td>3</td>\n",
       "      <td>Document Feeder is Low Quality</td>\n",
       "      <td>The ET-3850 is described as a home office prin...</td>\n",
       "      <td>0.199333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8810</th>\n",
       "      <td>HP OfficeJet Pro 9015e</td>\n",
       "      <td>2023-02-02</td>\n",
       "      <td>3</td>\n",
       "      <td>Great printer, when it's \"online\".</td>\n",
       "      <td>Fast printer and great quality but I've had co...</td>\n",
       "      <td>0.194672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Review Model Review date  Review rating  \\\n",
       "1593           HP ENVY 6055e  2021-12-03              3   \n",
       "5238      Canon PIXMA TR4720  2023-08-16              2   \n",
       "7068         Epson - ET-4850  2023-05-14              1   \n",
       "2076         Epson - ET-2800  2023-02-28              2   \n",
       "3767      Canon PIXMA TR4720  2023-06-07              1   \n",
       "4819         Epson - XP-6100  2022-10-26              3   \n",
       "6853   HP ENVY Inspire 7255e  2023-03-29              3   \n",
       "4597         Epson - XP-6100  2023-08-20              1   \n",
       "2778         Epson - ET-3850  2023-03-07              3   \n",
       "8810  HP OfficeJet Pro 9015e  2023-02-02              3   \n",
       "\n",
       "                                         Original title  \\\n",
       "1593                                        Low Quality   \n",
       "5238                               Low quality printing   \n",
       "7068                                  Very Poor Quality   \n",
       "2076                                                NaN   \n",
       "3767  Item had obviously been used. Ink cartridges w...   \n",
       "4819                                    Could be better   \n",
       "6853             Quality is poor unless you print a lot   \n",
       "4597                                             Clunky   \n",
       "2778                     Document Feeder is Low Quality   \n",
       "8810                 Great printer, when it's \"online\".   \n",
       "\n",
       "                                        Original review  \\\n",
       "1593  this printer disconnects all the time. I spend...   \n",
       "5238  It was easy to install, but the printing job s...   \n",
       "7068  I have had this printer for several months.  I...   \n",
       "2076  There‚Äôs only normal or high quality. There‚Äôs n...   \n",
       "3767  Printer did not produce quality copies. It arr...   \n",
       "4819  Just taking it out of the box the printers pla...   \n",
       "6853  I learned that you have to print often or else...   \n",
       "4597  Low quality constructionSlow Print speedPainfu...   \n",
       "2778  The ET-3850 is described as a home office prin...   \n",
       "8810  Fast printer and great quality but I've had co...   \n",
       "\n",
       "      TFIDF Similarity Score  \n",
       "1593                0.392702  \n",
       "5238                0.360529  \n",
       "7068                0.265875  \n",
       "2076                0.262055  \n",
       "3767                0.238766  \n",
       "4819                0.230578  \n",
       "6853                0.220677  \n",
       "4597                0.205049  \n",
       "2778                0.199333  \n",
       "8810                0.194672  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_and_sort('low quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d301cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
